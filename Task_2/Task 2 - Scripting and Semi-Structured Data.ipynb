{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Descripition \n",
    "\n",
    "In 2012, URL shortening service Bitly partnered with the US government website USA.gov to provide a feed of anonymous data gathered from users who shorten links ending with .gov or .mil.\n",
    "\n",
    "The text file comes in JSON format and here are some keys and their description. They are only the most important ones for this task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|key| description |\n",
    "|---|-----------|\n",
    "| a|Denotes information about the web browser and operating system|\n",
    "| tz | time zone |\n",
    "| r | URL the user come from |\n",
    "| u | URL where the user headed to |\n",
    "| t | Timestamp when the user start using the website in UNIX format |\n",
    "| hc | Timestamp when user exit the website in UNIX format |\n",
    "| cy | City from which the request intiated |\n",
    "| ll | Longitude and Latitude |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Script Details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All CSV files must have the following columns\n",
    "- web_browser\n",
    "        The web browser that has requested the service\n",
    "- operating_sys\n",
    "        operating system that intiated this request\n",
    "- from_url\n",
    "\n",
    "        The main URL the user came from\n",
    "\n",
    "    **note**:\n",
    "\n",
    "    If the retrived URL was in a long format `http://www.facebook.com/l/7AQEFzjSi/1.usa.gov/wfLQtf`\n",
    "\n",
    "     make it appear in the file in a short format like this `www.facebook.com`\n",
    "     \n",
    "    \n",
    "- to_url\n",
    "\n",
    "       The same applied like `to_url`\n",
    "   \n",
    "- city\n",
    "\n",
    "        The city from which the the request was sent\n",
    "    \n",
    "- longitude\n",
    "\n",
    "        The longitude where the request was sent\n",
    "- latitude\n",
    "\n",
    "        The latitude where the request was sent\n",
    "\n",
    "- time_zone\n",
    "        \n",
    "        The time zone that the city follow\n",
    "        \n",
    "- time_in\n",
    "\n",
    "        Time when the request started\n",
    "- time_out\n",
    "        \n",
    "        Time when the request is ended\n",
    "        \n",
    "        \n",
    "**NOTE** :\n",
    "\n",
    "Because that some instances of the file are incomplete, you may encouter some NaN values in your transforamtion. Make sure that the final dataframes have no NaNs at all."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Script itself must do the following before and after trasforamtion: \n",
    "    \n",
    "- One positional argument which is the directory path with that have the files.\n",
    "\n",
    "\n",
    "- One optional argument **-u**. If this argument is passed will maintain the UNIX format of timpe stamp and if not                passed the time stamps will be converted.\n",
    "\n",
    "\n",
    "- Check if the files have any dublicates in between **checksum** and print a messeage that indicate that.\n",
    "\n",
    "\n",
    "- Print a message after converting each file with the number of rows transformed and the path of this file\n",
    "\n",
    "\n",
    "- At the end of this script print the total excution time.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell, I tried to provide some helper code for better understanding and clearer vision\n",
    "\n",
    "-**HINT**- Those lines of code may be not helping at all with your task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a script can transform the JSON files to a DataFrame and commit each file to a sparete CSV file in the target directory and consider the following:\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd \n",
    "from pandas.io.json import json_normalize \n",
    "import json\n",
    "from subprocess import run, PIPE, Popen\n",
    "import subprocess\n",
    "import argparse\n",
    "import fnmatch\n",
    "import numpy as np\n",
    "import time\n",
    "import re\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path to search for json files ==>  /mnt/d/ITI/python_for_data_management/Task_2\n",
      "files detected :\n",
      " ['usa.gov_click_data_1.json', 'usa.gov_click_data_2.json', 'usa.gov_click_data_3.json']\n"
     ]
    }
   ],
   "source": [
    "path = os.getcwd()\n",
    "print(\"path to search for json files ==> \" , path)\n",
    "files=[]\n",
    "for file in listdir(path):\n",
    "    if '.json' in file:\n",
    "        files.append(file)\n",
    "print(\"files detected :\\n\", files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Duplicates: ['usa.gov_click_data_3.json']\n"
     ]
    }
   ],
   "source": [
    "checksums = {}\n",
    "duplicates = []\n",
    "\n",
    "for filename in files:\n",
    "    # Use Popen to call the md5sum utility\n",
    "    with Popen([\"md5sum\", filename], stdout=PIPE) as proc:\n",
    "        checksum, _ = proc.stdout.read().split()\n",
    "        \n",
    "        # Append duplicate to a list if the checksum is found\n",
    "        if checksum in checksums:\n",
    "            duplicates.append(filename)\n",
    "        checksums[checksum] = filename\n",
    "\n",
    "print(f\"Found Duplicates: {duplicates}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#parser = argparse.ArgumentParser()\n",
    "\n",
    "#parser.add_argument(\"dir\", help = \"Enter path of Directory\")\n",
    "\n",
    "#parser.add_argument(\"-u\", \"--unix\", action=\"store_true\", dest=\"unix\", default=False, help=\"This to manage time\")\n",
    "\n",
    "#args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in files:\n",
    "    To_Url_lst=[]\n",
    "    lst = []\n",
    "    Operating_System_lst = []\n",
    "    From_Url_lst=[]  \n",
    "    lst.clear()\n",
    "    Operating_System_lst.clear()\n",
    "    From_Url_lst.clear()\n",
    "    To_Url_lst.clear()\n",
    "    \n",
    "    records = [json.loads(line) for line in open(file)]\n",
    "    df = pd.DataFrame(records)\n",
    "    df = df[['a','tz','r','u','t','ll','hc','cy']]\n",
    "    df['web_Browser']= df.a.str.extract(r'^([a-zA-Z]*/)')   #extract any ch end with /   \n",
    "    df['web_Browser']= df.a.str.extract(r'^([a-zA-Z]*)')    #then remove   / extract chs only\n",
    "    df['operating_system']= df.a.str.extract(r'(\\([^(]+\\))', expand=True)\n",
    "    \n",
    "    for i in df['operating_system']:\n",
    "        i = str(i)\n",
    "        lst = i.split(\" \")\n",
    "        x = re.sub(\"\\(\",\"\",lst[0])\n",
    "        x = re.sub(\";\",\"\",x)\n",
    "        Operating_System_lst.append(x)\n",
    "    df['operating_system']= Operating_System_lst\n",
    "                                                     # OUTPut       //t.co/N\n",
    "    df['from_url'] = df.r.str.extract(r'(//[a-zA-Z]*.[a-zA-Z]*.[a-zA-Z]*)', expand=True)   # output //www.facebook.com\n",
    "    \n",
    "    for i in df['from_url']:\n",
    "        i = str(i)\n",
    "        x = re.sub(\"//\",\"\",str(i))\n",
    "        if \"/\" in x:\n",
    "            x = x[0:x.index(\"/\")]\n",
    "            From_Url_lst.append(x)\n",
    "        else:\n",
    "            From_Url_lst.append(x)\n",
    "    From_Url_lst\n",
    "    df['from_url'] = From_Url_lst\n",
    "    \n",
    "    df['to_url'] = df.u.str.extract(r'(.*[.gov])', expand=True)\n",
    "    #df['to_url'] = df.u.str.extract(r'(//[a-zA-Z]*.[a-zA-Z]*.[a-zA-Z])', expand=True) # remove the beggining http // ..\n",
    "    for i in df['to_url']:\n",
    "        i = str(i)\n",
    "        x = re.sub(\"http://\",\"\",str(i))\n",
    "        if \"/\" in x:\n",
    "            x = x[0:x.index(\"/\")]\n",
    "            To_Url_lst.append(x)\n",
    "        else:\n",
    "            To_Url_lst.append(x)\n",
    "    From_Url_lst\n",
    "    df['to_url'] = To_Url_lst\n",
    "    \n",
    "    df.rename(columns = {'tz' : 'time_zone', 'cy': 'city','t': 'time_in','hc':'time_out'}, inplace = True)\n",
    "    df['ll'] = df['ll'].fillna('')\n",
    "    df[['longitude','latitude']] = pd.DataFrame(df['ll'].values.tolist(), index = df.index)\n",
    "    df = df[['web_Browser','operating_system','from_url','to_url','city','longitude','latitude','time_zone','time_in','time_out']]\n",
    "    #df.replace(r'\\s+', np.nan)\n",
    "    df = df.replace(to_replace = \"nan\" , value = np.nan)\n",
    "    df = df.replace(to_replace = r'\\s+' , value = np.nan)\n",
    "    df = df.dropna(axis=0)\n",
    "    \n",
    "                  \n",
    "    df.to_csv(path+\"/target/\"+file+\".csv\" , header=True , index=False )\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>web_Browser</th>\n",
       "      <th>operating_system</th>\n",
       "      <th>from_url</th>\n",
       "      <th>to_url</th>\n",
       "      <th>city</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>time_zone</th>\n",
       "      <th>time_in</th>\n",
       "      <th>time_out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mozilla</td>\n",
       "      <td>Windows</td>\n",
       "      <td>www.facebook.com</td>\n",
       "      <td>www.ncbi.nlm.nih.gov</td>\n",
       "      <td>Danvers</td>\n",
       "      <td>42.576698</td>\n",
       "      <td>-70.954903</td>\n",
       "      <td>America/New_York</td>\n",
       "      <td>2012-03-16 22:40:47+00:00</td>\n",
       "      <td>2012-03-15 18:48:38+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mozilla</td>\n",
       "      <td>Windows</td>\n",
       "      <td>t.co</td>\n",
       "      <td>boxer.senate.gov</td>\n",
       "      <td>Washington</td>\n",
       "      <td>38.900700</td>\n",
       "      <td>-77.043098</td>\n",
       "      <td>America/New_York</td>\n",
       "      <td>2012-03-16 22:40:50+00:00</td>\n",
       "      <td>2012-03-16 21:45:41+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mozilla</td>\n",
       "      <td>Windows</td>\n",
       "      <td>www.shrewsbury-ma</td>\n",
       "      <td>www.shrewsbury-ma.gov</td>\n",
       "      <td>Shrewsbury</td>\n",
       "      <td>42.286499</td>\n",
       "      <td>-71.714699</td>\n",
       "      <td>America/New_York</td>\n",
       "      <td>2012-03-16 22:40:51+00:00</td>\n",
       "      <td>2010-05-12 17:53:31+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mozilla</td>\n",
       "      <td>Windows</td>\n",
       "      <td>www.shrewsbury-ma</td>\n",
       "      <td>www.shrewsbury-ma.gov</td>\n",
       "      <td>Shrewsbury</td>\n",
       "      <td>42.286499</td>\n",
       "      <td>-71.714699</td>\n",
       "      <td>America/New_York</td>\n",
       "      <td>2012-03-16 22:40:52+00:00</td>\n",
       "      <td>2010-05-12 17:55:06+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Mozilla</td>\n",
       "      <td>Windows</td>\n",
       "      <td>plus.url.google</td>\n",
       "      <td>www.nasa.gov</td>\n",
       "      <td>Luban</td>\n",
       "      <td>51.116699</td>\n",
       "      <td>15.283300</td>\n",
       "      <td>Europe/Warsaw</td>\n",
       "      <td>2012-03-16 17:40:55+00:00</td>\n",
       "      <td>2012-03-16 17:34:14+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3550</th>\n",
       "      <td>Mozilla</td>\n",
       "      <td>Windows</td>\n",
       "      <td>www.linkedin.com</td>\n",
       "      <td>www.nlm.nih.gov</td>\n",
       "      <td>Conshohocken</td>\n",
       "      <td>40.079800</td>\n",
       "      <td>-75.285500</td>\n",
       "      <td>America/New_York</td>\n",
       "      <td>2012-03-16 23:40:37+00:00</td>\n",
       "      <td>2012-03-16 21:07:12+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3553</th>\n",
       "      <td>Mozilla</td>\n",
       "      <td>Windows</td>\n",
       "      <td>www.shrewsbury-ma</td>\n",
       "      <td>www.shrewsbury-ma.gov</td>\n",
       "      <td>Shrewsbury</td>\n",
       "      <td>42.286499</td>\n",
       "      <td>-71.714699</td>\n",
       "      <td>America/New_York</td>\n",
       "      <td>2012-03-16 23:40:40+00:00</td>\n",
       "      <td>2010-05-12 17:53:31+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3554</th>\n",
       "      <td>Mozilla</td>\n",
       "      <td>Windows</td>\n",
       "      <td>www.shrewsbury-ma</td>\n",
       "      <td>www.shrewsbury-ma.gov</td>\n",
       "      <td>Shrewsbury</td>\n",
       "      <td>42.286499</td>\n",
       "      <td>-71.714699</td>\n",
       "      <td>America/New_York</td>\n",
       "      <td>2012-03-16 23:40:40+00:00</td>\n",
       "      <td>2010-05-12 17:55:06+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3556</th>\n",
       "      <td>Mozilla</td>\n",
       "      <td>Windows</td>\n",
       "      <td>www.facebook.com</td>\n",
       "      <td>www.okc.gov</td>\n",
       "      <td>Oklahoma City</td>\n",
       "      <td>35.471500</td>\n",
       "      <td>-97.518997</td>\n",
       "      <td>America/Chicago</td>\n",
       "      <td>2012-03-17 00:40:44+00:00</td>\n",
       "      <td>2011-06-08 15:50:47+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3559</th>\n",
       "      <td>Mozilla</td>\n",
       "      <td>Windows</td>\n",
       "      <td>t.co</td>\n",
       "      <td>herndon-va.gov</td>\n",
       "      <td>Mc Lean</td>\n",
       "      <td>38.935799</td>\n",
       "      <td>-77.162102</td>\n",
       "      <td>America/New_York</td>\n",
       "      <td>2012-03-16 23:40:49+00:00</td>\n",
       "      <td>2011-08-09 17:47:50+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1444 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     web_Browser operating_system           from_url                 to_url  \\\n",
       "0        Mozilla          Windows   www.facebook.com   www.ncbi.nlm.nih.gov   \n",
       "2        Mozilla          Windows               t.co       boxer.senate.gov   \n",
       "4        Mozilla          Windows  www.shrewsbury-ma  www.shrewsbury-ma.gov   \n",
       "5        Mozilla          Windows  www.shrewsbury-ma  www.shrewsbury-ma.gov   \n",
       "6        Mozilla          Windows    plus.url.google           www.nasa.gov   \n",
       "...          ...              ...                ...                    ...   \n",
       "3550     Mozilla          Windows   www.linkedin.com        www.nlm.nih.gov   \n",
       "3553     Mozilla          Windows  www.shrewsbury-ma  www.shrewsbury-ma.gov   \n",
       "3554     Mozilla          Windows  www.shrewsbury-ma  www.shrewsbury-ma.gov   \n",
       "3556     Mozilla          Windows   www.facebook.com            www.okc.gov   \n",
       "3559     Mozilla          Windows               t.co         herndon-va.gov   \n",
       "\n",
       "               city  longitude   latitude         time_zone  \\\n",
       "0           Danvers  42.576698 -70.954903  America/New_York   \n",
       "2        Washington  38.900700 -77.043098  America/New_York   \n",
       "4        Shrewsbury  42.286499 -71.714699  America/New_York   \n",
       "5        Shrewsbury  42.286499 -71.714699  America/New_York   \n",
       "6             Luban  51.116699  15.283300     Europe/Warsaw   \n",
       "...             ...        ...        ...               ...   \n",
       "3550   Conshohocken  40.079800 -75.285500  America/New_York   \n",
       "3553     Shrewsbury  42.286499 -71.714699  America/New_York   \n",
       "3554     Shrewsbury  42.286499 -71.714699  America/New_York   \n",
       "3556  Oklahoma City  35.471500 -97.518997   America/Chicago   \n",
       "3559        Mc Lean  38.935799 -77.162102  America/New_York   \n",
       "\n",
       "                       time_in                  time_out  \n",
       "0    2012-03-16 22:40:47+00:00 2012-03-15 18:48:38+00:00  \n",
       "2    2012-03-16 22:40:50+00:00 2012-03-16 21:45:41+00:00  \n",
       "4    2012-03-16 22:40:51+00:00 2010-05-12 17:53:31+00:00  \n",
       "5    2012-03-16 22:40:52+00:00 2010-05-12 17:55:06+00:00  \n",
       "6    2012-03-16 17:40:55+00:00 2012-03-16 17:34:14+00:00  \n",
       "...                        ...                       ...  \n",
       "3550 2012-03-16 23:40:37+00:00 2012-03-16 21:07:12+00:00  \n",
       "3553 2012-03-16 23:40:40+00:00 2010-05-12 17:53:31+00:00  \n",
       "3554 2012-03-16 23:40:40+00:00 2010-05-12 17:55:06+00:00  \n",
       "3556 2012-03-17 00:40:44+00:00 2011-06-08 15:50:47+00:00  \n",
       "3559 2012-03-16 23:40:49+00:00 2011-08-09 17:47:50+00:00  \n",
       "\n",
       "[1444 rows x 10 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
